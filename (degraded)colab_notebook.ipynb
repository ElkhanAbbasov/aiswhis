{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b07df50b",
   "metadata": {},
   "source": [
    "# Turkish XTTS Fine-tuning on Google Colab\n",
    "\n",
    "This notebook guides you through fine-tuning XTTSv2 for Turkish language."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "067ce707",
   "metadata": {},
   "source": [
    "## Cell 1: Check GPU\n",
    "\n",
    "Verify L4 GPU is active. Expected output should show \"NVIDIA L4\" with ~24GB memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416279f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify L4 GPU is active\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71db499",
   "metadata": {},
   "source": [
    "## Cell 2: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aeca50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch with CUDA 12.1\n",
    "!pip install --upgrade pip\n",
    "!pip install \"torch==2.3.1\" \"torchaudio==2.3.1\" --index-url https://download.pytorch.org/whl/cu121\n",
    "\n",
    "# Install Coqui TTS and trainer\n",
    "!pip install \"TTS==0.22.0\" \"coqui-tts-trainer\"\n",
    "\n",
    "# Configure safe globals\n",
    "import torch\n",
    "from TTS.tts.configs.xtts_config import XttsConfig\n",
    "from TTS.tts.models.xtts import XttsAudioConfig, XttsArgs\n",
    "from TTS.config.shared_configs import BaseDatasetConfig\n",
    "\n",
    "torch.serialization.add_safe_globals([\n",
    "    XttsConfig, XttsAudioConfig, BaseDatasetConfig, XttsArgs\n",
    "])\n",
    "\n",
    "print(\"‚úì Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0315308",
   "metadata": {},
   "source": [
    "## Cell 3: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "950b1051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Set your dataset path\n",
    "DATASET_ROOT = \"/content/drive/MyDrive/xtts_tr_dataset\"\n",
    "METADATA_FILE = f\"{DATASET_ROOT}/metadata.txt\"\n",
    "\n",
    "# Quick check\n",
    "import os\n",
    "print(\"Wav count:\", len([f for f in os.listdir(f\"{DATASET_ROOT}/wavs\") if f.endswith(\".wav\")]))\n",
    "print(\"Metadata exists:\", os.path.isfile(METADATA_FILE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4737efd9",
   "metadata": {},
   "source": [
    "## üìã Dataset Structure Required\n",
    "\n",
    "Before proceeding, make sure your Google Drive has this structure:\n",
    "\n",
    "```\n",
    "MyDrive/\n",
    "  ‚îî‚îÄ‚îÄ xtts_tr_dataset/\n",
    "      ‚îú‚îÄ‚îÄ metadata.txt          ‚Üê One line per audio file\n",
    "      ‚îî‚îÄ‚îÄ wavs/\n",
    "          ‚îú‚îÄ‚îÄ 0001.wav\n",
    "          ‚îú‚îÄ‚îÄ 0002.wav\n",
    "          ‚îú‚îÄ‚îÄ 0003.wav\n",
    "          ‚îî‚îÄ‚îÄ ... (more files)\n",
    "```\n",
    "\n",
    "**metadata.txt format** (pipe-separated):\n",
    "```\n",
    "FILE_ID|TRANSCRIPTION|TRANSCRIPTION\n",
    "```\n",
    "\n",
    "Example:\n",
    "```\n",
    "0001|Merhaba, benim adƒ±m Ay≈üe.|Merhaba, benim adƒ±m Ay≈üe.\n",
    "0002|Bug√ºn hava √ßok g√ºzel.|Bug√ºn hava √ßok g√ºzel.\n",
    "```\n",
    "\n",
    "‚ö†Ô∏è **Important**: \n",
    "- File IDs in metadata.txt must match WAV filenames (without .wav extension)\n",
    "- All audio should be mono, 22050 Hz, 16-bit PCM\n",
    "- Each audio clip should be 3-15 seconds long\n",
    "- Use clear, consistent speaker voice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db6467d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Validate your dataset structure\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "DATASET_ROOT = \"/content/drive/MyDrive/xtts_tr_dataset\"\n",
    "METADATA_FILE = f\"{DATASET_ROOT}/metadata.txt\"\n",
    "WAVS_DIR = f\"{DATASET_ROOT}/wavs\"\n",
    "\n",
    "print(\"üîç Checking dataset structure...\\n\")\n",
    "\n",
    "# Check if folders exist\n",
    "if not os.path.exists(DATASET_ROOT):\n",
    "    print(f\"‚ùå Dataset folder not found: {DATASET_ROOT}\")\n",
    "    print(\"   Please create it in your Google Drive\")\n",
    "elif not os.path.exists(WAVS_DIR):\n",
    "    print(f\"‚ùå Wavs folder not found: {WAVS_DIR}\")\n",
    "    print(\"   Please create a 'wavs' subfolder\")\n",
    "elif not os.path.exists(METADATA_FILE):\n",
    "    print(f\"‚ùå metadata.txt not found: {METADATA_FILE}\")\n",
    "    print(\"   Please create metadata.txt with your transcriptions\")\n",
    "else:\n",
    "    # Count files\n",
    "    wav_files = [f for f in os.listdir(WAVS_DIR) if f.endswith(\".wav\")]\n",
    "    \n",
    "    # Read metadata\n",
    "    with open(METADATA_FILE, 'r', encoding='utf-8') as f:\n",
    "        metadata_lines = [line.strip() for line in f if line.strip()]\n",
    "    \n",
    "    print(f\"‚úÖ Dataset structure looks good!\")\n",
    "    print(f\"   üìÅ Dataset root: {DATASET_ROOT}\")\n",
    "    print(f\"   üîä WAV files found: {len(wav_files)}\")\n",
    "    print(f\"   üìÑ Metadata entries: {len(metadata_lines)}\")\n",
    "    \n",
    "    # Check for mismatches\n",
    "    metadata_ids = set()\n",
    "    for line in metadata_lines:\n",
    "        parts = line.split('|')\n",
    "        if len(parts) >= 2:\n",
    "            metadata_ids.add(parts[0])\n",
    "    \n",
    "    wav_ids = set(Path(f).stem for f in wav_files)\n",
    "    \n",
    "    missing_wavs = metadata_ids - wav_ids\n",
    "    missing_metadata = wav_ids - metadata_ids\n",
    "    \n",
    "    if missing_wavs:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: {len(missing_wavs)} files in metadata.txt but no WAV file:\")\n",
    "        for fid in list(missing_wavs)[:5]:\n",
    "            print(f\"      - {fid}.wav is missing\")\n",
    "    \n",
    "    if missing_metadata:\n",
    "        print(f\"\\n‚ö†Ô∏è  Warning: {len(missing_metadata)} WAV files have no metadata entry:\")\n",
    "        for fid in list(missing_metadata)[:5]:\n",
    "            print(f\"      - {fid}.wav needs a line in metadata.txt\")\n",
    "    \n",
    "    if not missing_wavs and not missing_metadata:\n",
    "        print(f\"\\nüéâ Perfect! All files match. Ready to train!\")\n",
    "        print(f\"\\nüìä Sample metadata entries:\")\n",
    "        for line in metadata_lines[:3]:\n",
    "            print(f\"   {line}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41118703",
   "metadata": {},
   "source": [
    "## Cell 4: Create Training Script\n",
    "\n",
    "Run the cell below to create `train_gpt_xtts_tr.py` directly in Colab. This uses the `%%writefile` magic command to write the entire training script to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83809db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Your notebook file cannot be opened directly inside this environment, so I cannot rewrite it in `.ipynb` format.\n",
    "I **can** give you a **complete new Colab notebook** in copy-paste form.\n",
    "Paste this into a **new Colab notebook** ‚Üí it will work immediately.\n",
    "\n",
    "---\n",
    "\n",
    "# **Your New Working Colab Notebook (copy‚Äìpaste)**\n",
    "\n",
    "---\n",
    "\n",
    "## **1. Runtime preparation**\n",
    "\n",
    "```python\n",
    "!nvidia-smi\n",
    "!python --version\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **2. Clone aiswhis**\n",
    "\n",
    "```python\n",
    "%cd /content\n",
    "!git clone https://github.com/ElkhanAbbasov/aiswhis\n",
    "%cd aiswhis\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **3. Install dependencies**\n",
    "\n",
    "```python\n",
    "!pip install -q -r requirements.txt\n",
    "!pip install -q trainer\n",
    "!pip install -q torch torchaudio\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **4. Mount Google Drive**\n",
    "\n",
    "```python\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **5. Verify dataset folder**\n",
    "\n",
    "```python\n",
    "!ls /content/drive/MyDrive/xtts_tr_dataset\n",
    "```\n",
    "\n",
    "You must see your `.wav` files.\n",
    "\n",
    "---\n",
    "\n",
    "## **6. Prepare project paths**\n",
    "\n",
    "```python\n",
    "import os\n",
    "\n",
    "os.makedirs(\"/content/aiswhis/run_tr_tr/training/XTTS_v2_tr_base\", exist_ok=True)\n",
    "\n",
    "!cp /content/aiswhis/pretrained/XTTS_v2/dvae.pth \\\n",
    "    /content/aiswhis/run_tr_tr/training/XTTS_v2_tr_base/\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **7. PATCH the training script to disable evaluation**\n",
    "\n",
    "This fixes your current crash.\n",
    "\n",
    "```python\n",
    "%cd /content/aiswhis\n",
    "from pathlib import Path\n",
    "import re\n",
    "\n",
    "p = Path(\"train_gpt_xtts_tr.py\")\n",
    "s = p.read_text()\n",
    "\n",
    "# Disable eval split\n",
    "s = s.replace(\"eval_split=True\", \"eval_split=False\")\n",
    "\n",
    "# Force eval_samples = None\n",
    "s = re.sub(\n",
    "    r\"(train_samples\\s*,\\s*eval_samples\\s*=\\s*load_tts_samples\\([^)]*\\))\",\n",
    "    r\"\\1\\n    eval_samples = None\",\n",
    "    s,\n",
    "    count=1,\n",
    ")\n",
    "\n",
    "# Disable trainer evaluation\n",
    "s = s.replace(\"run_eval=True\", \"run_eval=False\")\n",
    "\n",
    "p.write_text(s)\n",
    "print(\"train_gpt_xtts_tr.py patched.\")\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## **8. Start Training**\n",
    "\n",
    "```python\n",
    "%cd /content/aiswhis\n",
    "!python train_gpt_xtts_tr.py\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "# **End of Notebook**\n",
    "\n",
    "Paste these cells into a new Colab notebook exactly in this order.\n",
    "No modifications needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0530f5d4",
   "metadata": {},
   "source": [
    "## Cell 5: Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43213457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set environment variables\n",
    "os.environ[\"XTTS_TR_DATASET_ROOT\"] = \"/content/drive/MyDrive/xtts_tr_dataset\"\n",
    "os.environ[\"XTTS_TR_METADATA_FILE\"] = \"/content/drive/MyDrive/xtts_tr_dataset/metadata.txt\"\n",
    "\n",
    "# Start training\n",
    "!python train_gpt_xtts_tr.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72ef8d0a",
   "metadata": {},
   "source": [
    "## Cell 6: Monitor Training (Optional)\n",
    "\n",
    "Run this in a separate cell while training is running."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e6593f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load TensorBoard\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir ./run_tr_tr/training/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9c698b9",
   "metadata": {},
   "source": [
    "## Cell 7: Test Inference After Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1630862d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob, os\n",
    "from TTS.api import TTS\n",
    "\n",
    "# Find latest run dir\n",
    "run_root = \"/content/run_tr_tr/training\"\n",
    "runs = sorted(glob.glob(os.path.join(run_root, \"XTTSv2_Turkish_FT-*\")))\n",
    "assert runs, \"No runs found\"\n",
    "model_dir = runs[-1]\n",
    "\n",
    "model_path = os.path.join(model_dir, \"best_model.pth\")\n",
    "config_path = os.path.join(model_dir, \"config.json\")\n",
    "\n",
    "print(\"Using model:\", model_path)\n",
    "\n",
    "# Initialize TTS\n",
    "tts = TTS(\n",
    "    model_path=model_path,\n",
    "    config_path=config_path,\n",
    "    gpu=True,\n",
    ")\n",
    "\n",
    "# Generate sample\n",
    "speaker_wav = \"/content/drive/MyDrive/xtts_tr_dataset/wavs/0001.wav\"\n",
    "\n",
    "tts.tts_to_file(\n",
    "    text=\"Merhaba, ben senin T√ºrk√ße konu≈üan yapay zeka asistanƒ±nƒ±m.\",\n",
    "    file_path=\"sample_tr.wav\",\n",
    "    speaker_wav=speaker_wav,\n",
    "    language=\"tr\",\n",
    ")\n",
    "\n",
    "print(\"‚úì Generated: sample_tr.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b81cfcf",
   "metadata": {},
   "source": [
    "## Cell 8: Listen to Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c22568",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio(\"sample_tr.wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf98519a",
   "metadata": {},
   "source": [
    "## Cell 9: Generate More Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe25cce",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sentences = [\n",
    "    \"Bug√ºn hava √ßok g√ºzel.\",\n",
    "    \"Nasƒ±l yardƒ±mcƒ± olabilirim?\",\n",
    "    \"T√ºrk√ße konu≈ümak i√ßin ince ayarlanmƒ±≈ü bir modelim.\",\n",
    "    \"Yapay zeka teknolojisi hƒ±zla geli≈üiyor.\",\n",
    "]\n",
    "\n",
    "for i, text in enumerate(test_sentences):\n",
    "    output_file = f\"test_{i+1}.wav\"\n",
    "    tts.tts_to_file(\n",
    "        text=text,\n",
    "        file_path=output_file,\n",
    "        speaker_wav=speaker_wav,\n",
    "        language=\"tr\",\n",
    "    )\n",
    "    print(f\"‚úì Generated: {output_file}\")\n",
    "    display(Audio(output_file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c3835f",
   "metadata": {},
   "source": [
    "## Cell 10: Download Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce096f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zip the trained model\n",
    "!zip -r trained_model.zip {model_dir}\n",
    "\n",
    "# Download to your computer\n",
    "from google.colab import files\n",
    "files.download('trained_model.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080bfcd4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d8ef2ffe",
   "metadata": {},
   "source": [
    "## Tips\n",
    "\n",
    "1. **Save checkpoints to Drive**: Modify `OUT_PATH` in training script to save to Drive\n",
    "2. **Resume training**: Set `restore_path` to your checkpoint\n",
    "3. **Monitor loss**: Loss should decrease to ~1.5-2.5 for good quality\n",
    "4. **Adjust batch size**: If OOM, reduce `BATCH_SIZE` in script\n",
    "\n",
    "## Expected Timeline\n",
    "\n",
    "- Setup: 5-10 minutes\n",
    "- Dataset upload: 10-30 minutes (depending on size)\n",
    "- Training: 4-8 hours for 2h dataset\n",
    "- Testing: 2-5 minutes\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### GPU Not Active"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10687547",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Force reconnect to L4\n",
    "from google.colab import runtime\n",
    "runtime.unassign()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a863928",
   "metadata": {},
   "source": [
    "### Training Too Slow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea23f826",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify GPU usage\n",
    "import torch\n",
    "print(\"CUDA available:\", torch.cuda.is_available())\n",
    "print(\"GPU:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04b9f56e",
   "metadata": {},
   "source": [
    "### OOM Error\n",
    "\n",
    "Reduce batch size in `train_gpt_xtts_tr.py`:\n",
    "```python\n",
    "BATCH_SIZE = 2  # or 1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**Pro tip**: Keep the Colab tab active and check progress every hour. Training can take 4-8 hours."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
